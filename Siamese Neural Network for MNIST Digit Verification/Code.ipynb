{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Load MNIST digits dataset","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf  # Import TensorFlow library\n\n# Load MNIST dataset\nmnist = tf.keras.datasets.mnist\n(X_train, y_train), (X_test, y_test) = mnist.load_data()\n\n# Output the shapes of training and testing data\nX_train.shape, y_train.shape, X_test.shape, y_test.shape","metadata":{"execution":{"iopub.status.busy":"2023-07-03T05:24:57.744622Z","iopub.execute_input":"2023-07-03T05:24:57.744967Z","iopub.status.idle":"2023-07-03T05:25:07.961090Z","shell.execute_reply.started":"2023-07-03T05:24:57.744944Z","shell.execute_reply":"2023-07-03T05:25:07.960020Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n  warnings.warn(f\"file system plugins are not loaded: {e}\")\n","output_type":"stream"},{"name":"stdout","text":"Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n11490434/11490434 [==============================] - 0s 0us/step\n","output_type":"stream"},{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"((60000, 28, 28), (60000,), (10000, 28, 28), (10000,))"},"metadata":{}}]},{"cell_type":"markdown","source":"## Building Siamese Neural Network for Image Comparison","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.layers import Input, Conv2D, BatchNormalization, ReLU, Reshape, Dense\nfrom tensorflow.keras.layers import GlobalAveragePooling2D, Concatenate\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras import Sequential\n\n# Create input placeholders\ninput_shape = (28, 28)\nimg_A_inp = Input(shape=input_shape, name='img_A_inp')\nimg_B_inp = Input(shape=input_shape, name='img_B_inp')\n\n# Function to create a CNN block\ndef create_cnn_block(depth):\n    model = Sequential()\n    model.add(Conv2D(depth, kernel_size=3, strides=1))\n    model.add(BatchNormalization())\n    model.add(ReLU())\n    return model\n\n# Create the shared CNN\ncnn = Sequential()\ncnn.add(Reshape((28, 28, 1)))\n\nDEPTH = 64\ncnn.add(create_cnn_block(DEPTH))\ncnn.add(create_cnn_block(DEPTH*2))\ncnn.add(create_cnn_block(DEPTH*4))\ncnn.add(create_cnn_block(DEPTH*8))\ncnn.add(GlobalAveragePooling2D())\ncnn.add(Dense(64, activation='relu'))\n\n# Apply the shared CNN to both inputs\nfeature_vector_A = cnn(img_A_inp)\nfeature_vector_B = cnn(img_B_inp)\n\n# Concatenate feature vectors from both images\nconcat = Concatenate()([feature_vector_A, feature_vector_B])\n\n# Add a Dense layer to perform final classification\ndense = Dense(64, activation='relu')(concat)\noutput = Dense(1, activation='sigmoid')(dense)\n\n# Create the final model\nmodel = Model(inputs=[img_A_inp, img_B_inp], outputs=output)\n\n# Print a summary of the model\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2023-07-03T05:25:07.963163Z","iopub.execute_input":"2023-07-03T05:25:07.964132Z","iopub.status.idle":"2023-07-03T05:25:13.064762Z","shell.execute_reply.started":"2023-07-03T05:25:07.964098Z","shell.execute_reply":"2023-07-03T05:25:13.064054Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Model: \"model\"\n__________________________________________________________________________________________________\n Layer (type)                   Output Shape         Param #     Connected to                     \n==================================================================================================\n img_A_inp (InputLayer)         [(None, 28, 28)]     0           []                               \n                                                                                                  \n img_B_inp (InputLayer)         [(None, 28, 28)]     0           []                               \n                                                                                                  \n sequential_4 (Sequential)      (None, 64)           1586496     ['img_A_inp[0][0]',              \n                                                                  'img_B_inp[0][0]']              \n                                                                                                  \n concatenate (Concatenate)      (None, 128)          0           ['sequential_4[0][0]',           \n                                                                  'sequential_4[1][0]']           \n                                                                                                  \n dense_1 (Dense)                (None, 64)           8256        ['concatenate[0][0]']            \n                                                                                                  \n dense_2 (Dense)                (None, 1)            65          ['dense_1[0][0]']                \n                                                                                                  \n==================================================================================================\nTotal params: 1,594,817\nTrainable params: 1,592,897\nNon-trainable params: 1,920\n__________________________________________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Random Sampling & Dimension Confirmation of Training Images and Labels","metadata":{}},{"cell_type":"code","source":"import numpy as np\n\n# Randomly select 300 indices from the number of training examples\nrandom_indices = np.random.choice(X_train.shape[0], 300, replace=False)\n\n# Use these indices to select a random sample of 300 images and their corresponding labels\nX_train_sample, y_train_sample = X_train[random_indices], y_train[random_indices]\n\n# Print the shapes of the sampled images and labels to confirm their dimensions\nX_train_sample.shape, y_train_sample.shape","metadata":{"execution":{"iopub.status.busy":"2023-07-03T08:52:56.548005Z","iopub.execute_input":"2023-07-03T08:52:56.548361Z","iopub.status.idle":"2023-07-03T08:52:56.581497Z","shell.execute_reply.started":"2023-07-03T08:52:56.548333Z","shell.execute_reply":"2023-07-03T08:52:56.579980Z"},"trusted":true},"execution_count":3,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[3], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Randomly select 300 indices from the number of training examples\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m random_indices \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mchoice(\u001b[43mX_train\u001b[49m\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m300\u001b[39m, replace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Use these indices to select a random sample of 300 images and their corresponding labels\u001b[39;00m\n\u001b[1;32m      7\u001b[0m X_train_sample, y_train_sample \u001b[38;5;241m=\u001b[39m X_train[random_indices], y_train[random_indices]\n","\u001b[0;31mNameError\u001b[0m: name 'X_train' is not defined"],"ename":"NameError","evalue":"name 'X_train' is not defined","output_type":"error"}]},{"cell_type":"markdown","source":"## Possible pairs for Siamese network","metadata":{}},{"cell_type":"code","source":"# Calculate and return the square of the number of training samples \nlen(X_train_sample) ** 2\n","metadata":{"execution":{"iopub.status.busy":"2023-07-03T05:25:13.089050Z","iopub.execute_input":"2023-07-03T05:25:13.089591Z","iopub.status.idle":"2023-07-03T05:25:13.096053Z","shell.execute_reply.started":"2023-07-03T05:25:13.089560Z","shell.execute_reply":"2023-07-03T05:25:13.095056Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"90000"},"metadata":{}}]},{"cell_type":"markdown","source":"## Generate pairs of images,labels to train Siamese Network","metadata":{}},{"cell_type":"code","source":"def make_paired_dataset(X, y):\n  # Get the total number of samples\n  num_samples = len(X)\n  \n  # Initialize lists for storing pairs of images and their labels\n  X_pairs, y_pairs = [], []\n\n  # Loop over all samples\n  for i in range(num_samples):\n    # For each sample, loop over all other samples to create pairs\n    for j in range(num_samples):\n      # Append the pair of images and their similarity label \n      #(1 if same class, 0 if different)\n      X_pairs.append([X[i], X[j]])\n      y_pairs.append(int(y[i] == y[j]))\n\n  # Convert lists of pairs to numpy arrays\n  X_pairs = np.array(X_pairs)\n  y_pairs = np.array(y_pairs)\n\n  # Return paired images and their labels\n  return X_pairs, y_pairs","metadata":{"execution":{"iopub.status.busy":"2023-07-03T08:47:57.936499Z","iopub.execute_input":"2023-07-03T08:47:57.936865Z","iopub.status.idle":"2023-07-03T08:47:57.952675Z","shell.execute_reply.started":"2023-07-03T08:47:57.936835Z","shell.execute_reply":"2023-07-03T08:47:57.951633Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"## Function call","metadata":{}},{"cell_type":"code","source":"make_paired_dataset(X_train_sample, y_train_sample)","metadata":{"execution":{"iopub.status.busy":"2023-07-03T05:25:13.107131Z","iopub.execute_input":"2023-07-03T05:25:13.107441Z","iopub.status.idle":"2023-07-03T05:25:13.489293Z","shell.execute_reply.started":"2023-07-03T05:25:13.107412Z","shell.execute_reply":"2023-07-03T05:25:13.488164Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"(array([[[[0, 0, 0, ..., 0, 0, 0],\n          [0, 0, 0, ..., 0, 0, 0],\n          [0, 0, 0, ..., 0, 0, 0],\n          ...,\n          [0, 0, 0, ..., 0, 0, 0],\n          [0, 0, 0, ..., 0, 0, 0],\n          [0, 0, 0, ..., 0, 0, 0]],\n \n         [[0, 0, 0, ..., 0, 0, 0],\n          [0, 0, 0, ..., 0, 0, 0],\n          [0, 0, 0, ..., 0, 0, 0],\n          ...,\n          [0, 0, 0, ..., 0, 0, 0],\n          [0, 0, 0, ..., 0, 0, 0],\n          [0, 0, 0, ..., 0, 0, 0]]],\n \n \n        [[[0, 0, 0, ..., 0, 0, 0],\n          [0, 0, 0, ..., 0, 0, 0],\n          [0, 0, 0, ..., 0, 0, 0],\n          ...,\n          [0, 0, 0, ..., 0, 0, 0],\n          [0, 0, 0, ..., 0, 0, 0],\n          [0, 0, 0, ..., 0, 0, 0]],\n \n         [[0, 0, 0, ..., 0, 0, 0],\n          [0, 0, 0, ..., 0, 0, 0],\n          [0, 0, 0, ..., 0, 0, 0],\n          ...,\n          [0, 0, 0, ..., 0, 0, 0],\n          [0, 0, 0, ..., 0, 0, 0],\n          [0, 0, 0, ..., 0, 0, 0]]],\n \n \n        [[[0, 0, 0, ..., 0, 0, 0],\n          [0, 0, 0, ..., 0, 0, 0],\n          [0, 0, 0, ..., 0, 0, 0],\n          ...,\n          [0, 0, 0, ..., 0, 0, 0],\n          [0, 0, 0, ..., 0, 0, 0],\n          [0, 0, 0, ..., 0, 0, 0]],\n \n         [[0, 0, 0, ..., 0, 0, 0],\n          [0, 0, 0, ..., 0, 0, 0],\n          [0, 0, 0, ..., 0, 0, 0],\n          ...,\n          [0, 0, 0, ..., 0, 0, 0],\n          [0, 0, 0, ..., 0, 0, 0],\n          [0, 0, 0, ..., 0, 0, 0]]],\n \n \n        ...,\n \n \n        [[[0, 0, 0, ..., 0, 0, 0],\n          [0, 0, 0, ..., 0, 0, 0],\n          [0, 0, 0, ..., 0, 0, 0],\n          ...,\n          [0, 0, 0, ..., 0, 0, 0],\n          [0, 0, 0, ..., 0, 0, 0],\n          [0, 0, 0, ..., 0, 0, 0]],\n \n         [[0, 0, 0, ..., 0, 0, 0],\n          [0, 0, 0, ..., 0, 0, 0],\n          [0, 0, 0, ..., 0, 0, 0],\n          ...,\n          [0, 0, 0, ..., 0, 0, 0],\n          [0, 0, 0, ..., 0, 0, 0],\n          [0, 0, 0, ..., 0, 0, 0]]],\n \n \n        [[[0, 0, 0, ..., 0, 0, 0],\n          [0, 0, 0, ..., 0, 0, 0],\n          [0, 0, 0, ..., 0, 0, 0],\n          ...,\n          [0, 0, 0, ..., 0, 0, 0],\n          [0, 0, 0, ..., 0, 0, 0],\n          [0, 0, 0, ..., 0, 0, 0]],\n \n         [[0, 0, 0, ..., 0, 0, 0],\n          [0, 0, 0, ..., 0, 0, 0],\n          [0, 0, 0, ..., 0, 0, 0],\n          ...,\n          [0, 0, 0, ..., 0, 0, 0],\n          [0, 0, 0, ..., 0, 0, 0],\n          [0, 0, 0, ..., 0, 0, 0]]],\n \n \n        [[[0, 0, 0, ..., 0, 0, 0],\n          [0, 0, 0, ..., 0, 0, 0],\n          [0, 0, 0, ..., 0, 0, 0],\n          ...,\n          [0, 0, 0, ..., 0, 0, 0],\n          [0, 0, 0, ..., 0, 0, 0],\n          [0, 0, 0, ..., 0, 0, 0]],\n \n         [[0, 0, 0, ..., 0, 0, 0],\n          [0, 0, 0, ..., 0, 0, 0],\n          [0, 0, 0, ..., 0, 0, 0],\n          ...,\n          [0, 0, 0, ..., 0, 0, 0],\n          [0, 0, 0, ..., 0, 0, 0],\n          [0, 0, 0, ..., 0, 0, 0]]]], dtype=uint8),\n array([1, 0, 0, ..., 1, 0, 1]))"},"metadata":{}}]},{"cell_type":"code","source":"X_train_pairs, y_train_pairs = make_paired_dataset(X_train_sample, y_train_sample)\n\nX_train_pairs.shape, y_train_pairs.shape","metadata":{"execution":{"iopub.status.busy":"2023-07-03T05:25:13.491017Z","iopub.execute_input":"2023-07-03T05:25:13.491372Z","iopub.status.idle":"2023-07-03T05:25:14.061663Z","shell.execute_reply.started":"2023-07-03T05:25:13.491340Z","shell.execute_reply":"2023-07-03T05:25:14.060690Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"((90000, 2, 28, 28), (90000,))"},"metadata":{}}]},{"cell_type":"markdown","source":"## Random Sampling of Test Images, Labels for Evaluation","metadata":{}},{"cell_type":"code","source":"# Randomly select 150 indices from the number of test examples\nrandom_indices = np.random.choice(X_test.shape[0], 150, replace=False)\n\n# Use these indices to select a random sample of 150 images and their corresponding labels from the test dataset\nX_test_sample, y_test_sample = X_test[random_indices], y_test[random_indices]\n\n# Print the shapes of the sampled test images and labels to confirm their dimensions\nX_test_sample.shape, y_test_sample.shape","metadata":{"execution":{"iopub.status.busy":"2023-07-03T08:52:41.668593Z","iopub.execute_input":"2023-07-03T08:52:41.669059Z","iopub.status.idle":"2023-07-03T08:52:42.234370Z","shell.execute_reply.started":"2023-07-03T08:52:41.669024Z","shell.execute_reply":"2023-07-03T08:52:42.228195Z"},"trusted":true},"execution_count":2,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[2], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Randomly select 150 indices from the number of test examples\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m random_indices \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mchoice(X_test\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m150\u001b[39m, replace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Use these indices to select a random sample of 150 images and their corresponding labels from the test dataset\u001b[39;00m\n\u001b[1;32m      5\u001b[0m X_test_sample, y_test_sample \u001b[38;5;241m=\u001b[39m X_test[random_indices], y_test[random_indices]\n","\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"],"ename":"NameError","evalue":"name 'np' is not defined","output_type":"error"}]},{"cell_type":"code","source":"X_test_pairs, y_test_pairs = make_paired_dataset(X_test_sample, y_test_sample)\n\nX_test_pairs.shape, y_test_pairs.shape","metadata":{"execution":{"iopub.status.busy":"2023-07-03T05:25:14.073656Z","iopub.execute_input":"2023-07-03T05:25:14.074037Z","iopub.status.idle":"2023-07-03T05:25:14.170561Z","shell.execute_reply.started":"2023-07-03T05:25:14.074006Z","shell.execute_reply":"2023-07-03T05:25:14.169670Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"((22500, 2, 28, 28), (22500,))"},"metadata":{}}]},{"cell_type":"markdown","source":"## Model Compilation","metadata":{}},{"cell_type":"code","source":"model.compile(loss='binary_crossentropy',\n              optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n              metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2023-07-03T05:25:14.173628Z","iopub.execute_input":"2023-07-03T05:25:14.173989Z","iopub.status.idle":"2023-07-03T05:25:14.192930Z","shell.execute_reply.started":"2023-07-03T05:25:14.173963Z","shell.execute_reply":"2023-07-03T05:25:14.191913Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"## Instantiate the EarlyStopping callback","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.callbacks import EarlyStopping\n\n# If the model's validation loss doesn't improve for 3 consecutive epochs, \n# the training will be stopped to prevent overfitting\nes = EarlyStopping(patience=3)","metadata":{"execution":{"iopub.status.busy":"2023-07-03T05:25:14.194417Z","iopub.execute_input":"2023-07-03T05:25:14.194778Z","iopub.status.idle":"2023-07-03T05:25:14.200372Z","shell.execute_reply.started":"2023-07-03T05:25:14.194747Z","shell.execute_reply":"2023-07-03T05:25:14.199389Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":"# Training Siamese model","metadata":{}},{"cell_type":"code","source":"model.fit(\n    # Feed the pairs of training images into the model\n    # X_train_pairs[:, 0, :, :] represents the first image in each pair\n    # X_train_pairs[:, 1, :, :] represents the second image in each pair\n    [X_train_pairs[:, 0, :, :], X_train_pairs[:, 1, :, :]],\n          y=y_train_pairs,\n          validation_split=0.3, \n          epochs=100,\n          batch_size=32,\n          callbacks=[es])","metadata":{"execution":{"iopub.status.busy":"2023-07-03T05:25:14.201750Z","iopub.execute_input":"2023-07-03T05:25:14.202185Z","iopub.status.idle":"2023-07-03T05:42:03.496510Z","shell.execute_reply.started":"2023-07-03T05:25:14.202155Z","shell.execute_reply":"2023-07-03T05:42:03.495601Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"Epoch 1/30\n1969/1969 [==============================] - 109s 48ms/step - loss: 0.2591 - accuracy: 0.9069 - val_loss: 0.1733 - val_accuracy: 0.9277\nEpoch 2/30\n1969/1969 [==============================] - 93s 47ms/step - loss: 0.0961 - accuracy: 0.9581 - val_loss: 0.0661 - val_accuracy: 0.9724\nEpoch 3/30\n1969/1969 [==============================] - 103s 52ms/step - loss: 0.0223 - accuracy: 0.9928 - val_loss: 0.0109 - val_accuracy: 0.9974\nEpoch 4/30\n1969/1969 [==============================] - 94s 47ms/step - loss: 0.0100 - accuracy: 0.9969 - val_loss: 0.0295 - val_accuracy: 0.9898\nEpoch 5/30\n1969/1969 [==============================] - 93s 47ms/step - loss: 0.0065 - accuracy: 0.9980 - val_loss: 3.2225e-04 - val_accuracy: 1.0000\nEpoch 6/30\n1969/1969 [==============================] - 103s 52ms/step - loss: 0.0067 - accuracy: 0.9980 - val_loss: 2.7747e-04 - val_accuracy: 1.0000\nEpoch 7/30\n1969/1969 [==============================] - 103s 52ms/step - loss: 0.0053 - accuracy: 0.9985 - val_loss: 9.1646e-05 - val_accuracy: 1.0000\nEpoch 8/30\n1969/1969 [==============================] - 104s 53ms/step - loss: 0.0059 - accuracy: 0.9982 - val_loss: 0.0019 - val_accuracy: 0.9999\nEpoch 9/30\n1969/1969 [==============================] - 104s 53ms/step - loss: 0.0024 - accuracy: 0.9993 - val_loss: 0.5137 - val_accuracy: 0.8537\nEpoch 10/30\n1969/1969 [==============================] - 103s 52ms/step - loss: 0.0052 - accuracy: 0.9984 - val_loss: 3.6188e-04 - val_accuracy: 1.0000\n","output_type":"stream"},{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"<keras.callbacks.History at 0x7e3531d46350>"},"metadata":{}}]},{"cell_type":"markdown","source":"## Testing Model's Efficacy","metadata":{}},{"cell_type":"code","source":"# Select the first and eighteenth image from the test dataset\nimg_A, img_B = X_test[0], X_test[17]\n\n# Get the corresponding labels of the selected images\nlabel_A, label_B = y_test[0], y_test[17]\n\n# Print the labels of the selected images\nlabel_A, label_B","metadata":{"execution":{"iopub.status.busy":"2023-07-03T06:21:04.510042Z","iopub.execute_input":"2023-07-03T06:21:04.510437Z","iopub.status.idle":"2023-07-03T06:21:04.518816Z","shell.execute_reply.started":"2023-07-03T06:21:04.510407Z","shell.execute_reply":"2023-07-03T06:21:04.517619Z"},"trusted":true},"execution_count":15,"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"(7, 7)"},"metadata":{}}]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\n# Create new figure with set DPI=28, as MNIST image =(28,28)\nplt.figure(dpi=28)\n\n# Display img_A\nplt.imshow(img_A)","metadata":{"execution":{"iopub.status.busy":"2023-07-03T06:21:12.742181Z","iopub.execute_input":"2023-07-03T06:21:12.742533Z","iopub.status.idle":"2023-07-03T06:21:38.704499Z","shell.execute_reply.started":"2023-07-03T06:21:12.742504Z","shell.execute_reply":"2023-07-03T06:21:38.703589Z"},"trusted":true},"execution_count":16,"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"<matplotlib.image.AxesImage at 0x7e3532659870>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 179.2x134.4 with 1 Axes>","image/png":"iVBORw0KGgoAAAANSUhEUgAAAHQAAABzCAYAAABJnyafAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAAROAAAETgFCi5P8AAAGh0lEQVR4nO2dbWhbVRjHn6xp89bFrEuztplbqKPWrnYgLOhWoS0VqaP4YV1TocUvvuD8MIUpYzARlImjY2yZfrQfhm91E4SpgRKiznVrRLETl9LaepHitkq9Gtc0yWLjB9lNnpSb5eXeNPfZ8/t0/pyTe5/m3+eee3LPOVeXTCaTwJBBn2vDcDgMgiBAVVWVmvEwBRCPx8HlcoHVas3dUEEQ4Okd+8EEFjVjYwpgGZbAACa4nByTN3R0dBREUQSPxwM2mw3m5+fBBBaw6KyljJXJhbROc51cm2g0Cl1dXRAKhUoREqMQsoYajUbw+/3Q3NwMAACNjY0lC4opHNlLbn9/fynjYBRCNkMZbcKGEoMNJQYbSgw2lBhsKDHYUGKwocRgQ4nBhhKDDSUGG0oMNpQYbCgxcjZ0bm5OzTgYhZA11Ov1QiAQKGUsjALIGup0OkEURUnzjAVtIGuow+EAQRAgkUiUMh6mSGSnoLS3t0N7e3spY2EUgO9yiZHzRGs1WXz2EaS3DP2C9NTCJqkcj1WiOueHWJvnbyK98uNVJULUDJyhxGBDicGGEqMs+tBXX/kA6b0WETe4L8uHO7AUEhGkT/7RWXhgBRJc2Iq05fg9SOv936t2bs5QYrChxCiLS+6pwwNIv9aG/882hFLr5cQHdKiuqu0vpI+1for0ifoJqfx5pBrV7THjIU42lpNxpCdieJ1sh/FWSqSdEwBgm+d5pJv8OZ82bzhDicGGEoMNJUZZ9KGWsxMZWr7tnTYE8NZ1IP3mblfqs1/jnxSPdWzLIbr/0S+vIG25cg3pjd+ck8oPVmX8HClgrSacocRAGRoMBsHn84HD4QC73Q59fX1SHU9B0QYoQ91uN+j1euju7oZIJCL3GaaMQRk6PT0NMzMzMDY2BrW1taihVqagJK7fQNpyLqX/zWhrObtY8HluPIMf+W2vSn2Vw3/ej+pcI/jqpuYcEGRoU1MTjIyMqHg6Rm34pogYbCgxymIcqgX0W+9F+vTh00hX6iqk8icnu1HdxmuX1AssA85QYrChxOBLbo5MvexEeqcBP8b7Ob4slWuurt0YnjOUGGwoMdhQYnAfKkNsz06kf+g7kdHCgNQLBw5IZdN4UK2w7ghnKDHYUGKwocTgPlSG33rw/3q1DveZT/36GNJm36RUXss3G/GmGcRYNQUlGAxCLBaDgYEBcDqdcp9jyhRkqNvthkAgAHV1dbC4uIgM1cqMhWJYt369VB569FtUF16JIr1wFH8fhth36gWWB+iSOz09DVNTU1BTUwOzs7NrFRNTBDwFhRg8bCEGD1vSmHl9u1Q+b38X1T05sxdpwxfl0WdmwhlKDDaUGGwoMe7qPvTvwYeRvuI5JZVnE7dQ3c23NyNtALz6rFzgDCUGG0oMNpQYd1Ufqnc2IP3SkY+RNuhSX8fA5BCqq/2yPMedmXCGEoMNJQb5S65On/oTd5yfR3X7qvGC3/f/cUjlTUfw/zreMqN84QwlBsrQ8fFxuHDhAphMJmhoaOBNMzQIytBdu3ZBNBqFnp4e3jRDo6AMHR4ehurqavD5fFBfX48aanYKyo7UBhZvOM5kbfrO0X1S2TZZukW6SoIMPXjw4FrFwSgE3xQRgw0lBrlxaEVLE9LPffSZbNuW915E2nXmsioxlRLOUGKwocQgd8md2r8B6V5zWLbt5q/wPvKQXMtlRsrAGUoMNpQYbCgxNN+HRnvdSPt7j2e0MJcumDKAM5QYbCgx2FBiaL4P/X13BdJb9PJ9ZvoUEwCAyjAeh2p/FMqbZpBj1RSUixcvwsrKCgwODvKmGRpk1RSUSCQibZqRjmZnLNxlrJqCYjabpU0z2tra1iouxXhrsUUqX3rcheqS134qcTTqw1NQiMHDFmJoftjSeAjPznvi0ENZWl9XN5gygDOUGGwoMXK+5MbjcViGJRo/pxBjGZbAACYAANAlk7nNuwiHwxAIBKCyslKRMentX56KPZZSx9FyTPF4HFwuF1it1twNZbQB96HEYEOJkdc4dHR0FERRBI/HAzabragTe71eaG1thc7OzoKPke0l8IUcS4ndvLOtsS3kWPk+LMkrQ6PRKHR1dUEoFCo4yNs4nU4QRbGoYyj5Eni32w1LS0tgt9tXPZjIByXX2GZ7WCJHXoYajUbw+/3Q3NxcUIDpOBwOEAQBEonCXzGe/hJ4s7m4yWBK7eadvsa22JgyH5bkAt/lEoNviojBhhLjPxDJ1MwPL1fbAAAAAElFTkSuQmCC"},"metadata":{}}]},{"cell_type":"code","source":"plt.figure(dpi=28)\n\n# Display img_B\nplt.imshow(img_B)","metadata":{"execution":{"iopub.status.busy":"2023-07-03T06:22:38.064237Z","iopub.execute_input":"2023-07-03T06:22:38.064641Z","iopub.status.idle":"2023-07-03T06:22:38.297367Z","shell.execute_reply.started":"2023-07-03T06:22:38.064605Z","shell.execute_reply":"2023-07-03T06:22:38.296438Z"},"trusted":true},"execution_count":18,"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"<matplotlib.image.AxesImage at 0x7e353266f100>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 179.2x134.4 with 1 Axes>","image/png":"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"},"metadata":{}}]},{"cell_type":"markdown","source":"## Comparing Images with Siamese Neural Network: Binary Classification","metadata":{}},{"cell_type":"code","source":"# Predict if img_A and img_B are from the same class (True if prediction > 0.5)\nmodel.predict([img_A.reshape((1, 28, 28)), \n               img_B.reshape((1, 28, 28))]).flatten()[0] > 0.5","metadata":{"execution":{"iopub.status.busy":"2023-07-03T06:24:00.350574Z","iopub.execute_input":"2023-07-03T06:24:00.351463Z","iopub.status.idle":"2023-07-03T06:24:00.970091Z","shell.execute_reply.started":"2023-07-03T06:24:00.351429Z","shell.execute_reply":"2023-07-03T06:24:00.969004Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"1/1 [==============================] - 1s 561ms/step\n","output_type":"stream"},{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}]},{"cell_type":"markdown","source":"As predicted value is greater than 0.5, the output is True, indicating the model believes the images are of the same class","metadata":{}}]}